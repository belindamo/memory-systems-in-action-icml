{
  "turn_global_index": 262,
  "session_index": 29,
  "session_id": "sharegpt_nrCPDzJ_0",
  "turn_in_session": 0,
  "date": "2023/05/25 (Thu) 19:34",
  "role": "user",
  "content": "Classify the below papers into 10 appropriate categories\n\nPapers: \n\nMedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering https://proceedings.mlr.press/v174/pal22a.html\n\nMedical Exam Question Answering with Large-scale Reading Comprehension https://arxiv.org/pdf/1802.10279.pdf\n\nPubMedQA: A Dataset for Biomedical Research Question Answering https://www.aclweb.org/anthology/D19-1259.pdf\n\nemrQA: A Large Corpus for Question Answering on Electronic Medical Records https://www.aclweb.org/anthology/D18-1258.pdf\n\nQASC: A Dataset for Question Answering via Sentence Composition https://arxiv.org/pdf/1910.11473.pdf\n\nMMM: Multi-stage Multi-task Learning for Multi-choice Reading Comprehension https://arxiv.org/pdf/1910.00458.pdf\n\nSOCIAL IQA: Commonsense Reasoning about Social Interactions https://arxiv.org/pdf/1904.09728.pdf\n\nImproving Question Answering with External Knowledge https://arxiv.org/pdf/1902.00993.pdf\n\nQuestion Answering as Global Reasoning over Semantic Abstractions https://arxiv.org/pdf/1906.03672.pdf\n\nAutomatic Question Answering for Medical MCQs: Can It Go Further than Information Retrieval? https://www.aclweb.org/anthology/R19-1049.pdf\n\nOverview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering https://www.aclweb.org/anthology/W19-5039.pdf\n\nHEAD-QA: A Healthcare Dataset for Complex Reasoning https://www.aclweb.org/anthology/P19-1092.pdf\n\nImproving Retrieval-Based Question Answering with Deep Inference Models https://arxiv.org/pdf/1812.02971.pdf\n\nExplain Yourself! Leveraging Language Models for Commonsense Reasoning https://arxiv.org/pdf/1906.02361.pdf\n\nGenNet : Reading Comprehension with Multiple Choice Questions using Generation and Selection model https://arxiv.org/abs/2003.04360\n\nRethinking the Value of Transformer Components https://www.aclweb.org/anthology/2020.coling-main.529.pdf\n\nA Corpus for Evidence Based Medicine Summarisation https://www.aclweb.org/anthology/U10-1012.pdf\n\nAn overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0564-6\n\nQuestion-Driven Summarization of Answers to Consumer Health Questions https://arxiv.org/pdf/2005.09067.pdf\n\nA QUESTION-ENTAILMENT APPROACH TO QUESTION ANSWERING https://arxiv.org/pdf/1901.08079.pdf\n\nA dataset of clinically generated visual questions and answers about radiology images https://www.nature.com/articles/sdata2018251\n\nOverview of the Medical Question Answering Task at TREC 2017 LiveQA https://lhncbc.nlm.nih.gov/system/files/pub9773.pdf\n\nA Survey of Datasets for Biomedical Question Answering Systems https://thesai.org/Downloads/Volume8No7/Paper\\_67-A\\_Survey\\_of\\_Datasets\\_for\\_Biomedical\\_Question.pdf\n\nLessons from Natural Language Inference in the Clinical Domain https://arxiv.org/pdf/1808.06752.pdf\n\nBeyond SQuAD: How to Apply a Transformer QA Model to Your Data https://qa.fastforwardlabs.com/domain%20adaptation/transfer%20learning/specialized%20datasets/qa/medical%20qa/2020/07/22/QA-for-Specialized-Data.html\n\nApplying deep matching networks to Chinese medical question answering: a study and a dataset https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0761-8\n\nThe AI2 Reasoning Challenge (ARC) dataset http://ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf\n\nInterpretation of Natural Language Rules in Conversational Machine Reading https://arxiv.org/pdf/1809.01494.pdf\n\nMCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text https://www.aclweb.org/anthology/D13-1020.pdf\n\nThe Complexity of Math Problems \u2013 Linguistic, or Computational? https://uclnlp.github.io/ai4exams/\\_papers/I13-1009.pdf\n\nUniversity Entrance Examinations as a Benchmark Resource for NLP-based Problem Solving https://uclnlp.github.io/ai4exams/\\_papers/I13-1192.pdf\n\nOverview of Todai Robot Project and Evaluation Framework of its NLP-based Problem Solving https://uclnlp.github.io/ai4exams/\\_papers/todai\\_overview.pdf\n\nMachine Comprehension with Discourse Relations https://uclnlp.github.io/ai4exams/\\_papers/P15-1121.pdf\n\nMachine Comprehension with Syntax, Frames, and Semantics https://uclnlp.github.io/ai4exams/\\_papers/P15-2115.pdf\n\nLearning Answer-Entailing Structures for Machine Comprehension https://uclnlp.github.io/ai4exams/\\_papers/P15-1024.pdf\n\nA Strong Lexical Matching Method for the Machine Comprehension Test https://uclnlp.github.io/ai4exams/\\_papers/D15-1197.pdf\n\nTeaching Machines to Read and Comprehend https://arxiv.org/pdf/1506.03340.pdf\n\nTOWARDS AI-COMPLETE QUESTION ANSWERING : A SET OF PREREQUISITE TOY TASKS https://arxiv.org/pdf/1502.05698.pdf\n\nTHE GOLDILOCKS PRINCIPLE: READING CHILDREN\u2019S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS https://research.fb.com/wp-content/uploads/2016/11/the\\_goldilocks\\_principle\\_reading\\_children\\_s\\_books\\_with\\_explicit\\_memory\\_representations.pdf?\n\nMachine Comprehension Based on Learning to Rank https://uclnlp.github.io/ai4exams/\\_papers/1605.03284v2.pdf\n\nAttention-Based Convolutional Neural Network for Machine Comprehension https://uclnlp.github.io/ai4exams/\\_papers/1602.04341v1.pdf\n\nDynamic Entity Representation with Max-pooling Improves Machine Reading https://uclnlp.github.io/ai4exams/\\_papers/N16-1099.pdf\n\nA Parallel-Hierarchical Model for Machine Comprehension on Sparse Data https://uclnlp.github.io/ai4exams/\\_papers/1603.08884.pdf\n\nA Thorough Examination of the CNN/Daily Mail Reading Comprehension Task https://uclnlp.github.io/ai4exams/\\_papers/1606.02858v1.pdf\n\nSQuAD: 100,000+ Questions for Machine Comprehension of Text https://uclnlp.github.io/ai4exams/\\_papers/1606.05250v1.pdf\n\nCliCR: A Dataset of Clinical Case Reports for Machine Reading Comprehension https://arxiv.org/pdf/1803.09720.pdf\n\nCODAH: An Adversarially Authored Question-Answer Dataset for Common Sense https://arxiv.org/pdf/1904.04365.pdf\n\nCoQA: A Conversational Question Answering Challenge https://arxiv.org/pdf/1808.07042.pdf\n\nHOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering https://www.aclweb.org/anthology/D18-1259.pdf\n\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset https://arxiv.org/pdf/1611.09268.pdf\n\nLooking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences https://www.aclweb.org/anthology/N18-1023.pdf\n\nNatural Questions: a Benchmark for Question Answering Research https://persagen.com/files/misc/kwiatkowski2019natural.pdf\n\nNEWSQA: A MACHINE COMPREHENSION DATASET https://arxiv.org/pdf/1611.09830.pdf\n\nConstructing Datasets for Multi-hop Reading Comprehension Across Documents https://arxiv.org/pdf/1710.06481.pdf\n\nQuAC : Question Answering in Context https://arxiv.org/pdf/1808.07036.pdf\n\nRACE: Large-scale ReAding Comprehension Dataset From Examinations https://arxiv.org/pdf/1704.04683.pdf\n\nLSDSem 2017 Shared Task: The Story Cloze Test http://aclweb.org/anthology/W17-0906.pdf\n\nSWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference https://arxiv.org/abs/1808.05326\n\nRecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes https://www.aclweb.org/anthology/D18-1166.pdf\n\nThe NarrativeQA Reading Comprehension Challenge https://arxiv.org/pdf/1712.07040.pdf\n\nDROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs https://arxiv.org/pdf/1903.00161.pdf\n\nDuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension https://arxiv.org/pdf/1804.07927.pdf\n\nCOSMOS QA: Machine Reading Comprehension with Contextual Commonsense Reasoning https://arxiv.org/pdf/1909.00277.pdf\n\nRECLOR: A READING COMPREHENSION DATASET REQUIRING LOGICAL REASONING https://openreview.net/pdf?id=HJgJtT4tvB\n\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications https://www.aclweb.org/anthology/W18-2605.pdf\n\nQUASAR: DATASETS FOR QUESTION ANSWERING BY SEARCH AND READING https://arxiv.org/pdf/1707.03904.pdf\n\nSearchQA: A New Q&A Dataset Augmented with Context from a Search Engine https://arxiv.org/pdf/1704.05179.pdf\n\n9th Challenge on Question Answering over Linked Data (QALD-9) http://ceur-ws.org/Vol-2241/paper-06.pdf\n\nGood for figures and other ideas https://qa.fastforwardlabs.com/domain%20adaptation/transfer%20learning/specialized%20datasets/qa/medical%20qa/2020/07/22/QA-for-Specialized-Data.html\n\nBioASQ: A Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering http://bioasq.org/resources/papers/Tsatsaronis\\_et\\_al\\_AAAIIRKD2012\\_CR.pdf\n\nCOVID-QA: A Question Answering Dataset for COVID-19 https://www.aclweb.org/anthology/2020.nlpcovid19-acl.18.pdf\n\nSemantic Parsing on Freebase from Question-Answer Pairs https://cs.stanford.edu/~pliang/papers/freebase-emnlp2013.pdf\n\nLarge-scale Simple Question Answering with Memory Network https://arxiv.org/pdf/1506.02075.pdf\n\nGenerating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus https://www.aclweb.org/anthology/P16-1056.pdf\n\nOn Generating Characteristic-rich Question Sets for QA Evaluation https://sites.cs.ucsb.edu/~ysu/papers/emnlp16\\_graphquestions.pdf\n\nTriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension https://www.aclweb.org/anthology/P17-1147.pdf\n\nLC-QuAD: A Corpus for Complex Question Answering over Knowledge Graphs http://jens-lehmann.org/files/2017/iswc\\_lcquad.pdf\n\nKnow What You Don\u2019t Know: Unanswerable Questions for SQuAD https://arxiv.org/pdf/1806.03822.pdf\n\nThe Web as a Knowledge-base for Answering Complex Questions https://arxiv.org/abs/1803.06643\n\nFreebaseQA: A New Factoid QA Data Set Matching Trivia-Style Question-Answer Pairs with Freebase https://www.aclweb.org/anthology/N19-1028.pdf\n\nComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters https://arxiv.org/pdf/1809.09528.pdf\n\nNatural Questions: A Benchmark for Question Answering Research https://www.aclweb.org/anthology/Q19-1026.pdf\n\nMEASURING COMPOSITIONAL GENERALIZATION: A COMPREHENSIVE METHOD ON REALISTIC DATA https://arxiv.org/pdf/1912.09713.pdf\n\nLarge-scale Semantic Parsing via Schema Matching and Lexicon Extension https://www.aclweb.org/anthology/P13-1042.pdf\n\nWIKIQA: A Challenge Dataset for Open-Domain Question Answering https://pdfs.semanticscholar.org/8685/671ad8b1b1b5fe2b108c7002662b582ba277.pdf?\\_ga=2.255219788.515480105.1609930430-1235984517.1600607025&\\_gac=1.114743541.1607092635.Cj0KCQiA2af-BRDzARIsAIVQUOdNiV5qT\\_0YS1w4gKgpaTrSKxbqsipzwnWWzkdgQU7V98y7gdbJcUQaAnquEALw\\_wcB\n\nGood Question! Statistical Ranking for Question Generation https://www.aclweb.org/anthology/N10-1086.pdf\n\nGenerating Natural Language Question-Answer Pairs from a Knowledge Graph Using a RNN Based Question Generation Model https://www.aclweb.org/anthology/E17-1036.pdf\n\nLearning to Ask: Neural Question Generation for Reading Comprehension https://arxiv.org/pdf/1705.00106.pdf\n\nNeural Question Generation from Text: A Preliminary Study https://arxiv.org/pdf/1704.01792.pdf\n\nMachine Comprehension by Text-to-Text Neural Question Generation https://arxiv.org/pdf/1705.02012.pdf",
  "has_answer": false
}