{
  "turn_global_index": 235,
  "session_index": 22,
  "session_id": "sharegpt_Fva9GhV_0",
  "turn_in_session": 0,
  "date": "2023/05/24 (Wed) 20:13",
  "role": "user",
  "content": "Given the code below, can you implement the currently unimplemented crop\\_and\\_resize\\_bodyshot function?\n\nimport cv2\nimport numpy as np\nimport mediapipe as mp\nimport time\nfrom tqdm import tqdm\n\nfrom third\\_party.face\\_geometry import (\n PCF,\n get\\_metric\\_landmarks,\n procrustes\\_landmark\\_basis,\n)\n\n# MP objects\nmp\\_face\\_detection = mp.solutions.face\\_detection\nmp\\_face\\_mesh = mp.solutions.face\\_mesh\nmp\\_drawing = mp.solutions.drawing\\_utils\nmp\\_drawing\\_styles = mp.solutions.drawing\\_styles\n\n# Mediapipe stuff\npoints\\_idx = [33, 263, 61, 291, 199]\npoints\\_idx = points\\_idx + [key for (key, val) in procrustes\\_landmark\\_basis]\npoints\\_idx = list(set(points\\_idx))\npoints\\_idx.sort()\n\n# Constants estimated from experiments\n# In theory, 125 combinations are possible.\n# Let's prioritize yaw and pitch now and ignore roll.\nNUM\\_SAMPLES\\_PER\\_AXIS = 5\nYAW\\_ANCHORS = np.linspace(-60.0, 60.0, NUM\\_SAMPLES\\_PER\\_AXIS)\nPITCH\\_ANCHORS = np.linspace(-40.0, 40.0, NUM\\_SAMPLES\\_PER\\_AXIS)\nROLL\\_ANCHORS = np.linspace(-45.0, 45.0, NUM\\_SAMPLES\\_PER\\_AXIS)\n\nFACE\\_HEIGHT\\_EXPANSION\\_FACTOR = 0.25\nHEADSHOT\\_THRESHOLD = 0.30\nTARGET\\_HEADSHOT\\_COVERAGE = 0.4\ndef detect\\_faces(image, debug=False):\n '''\n Function to detect faces in a given image.\n Model selection is set to \"1\" which is a full range model which works\n at all distances.\n\n Args:\n image: Input image\n Returns:\n faces: A list of faces\n '''\n with mp\\_face\\_detection.FaceDetection(\n model\\_selection=1, min\\_detection\\_confidence=0.5) as face\\_detection:\n\n # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n results = face\\_detection.process(cv2.cvtColor(image, cv2.COLOR\\_BGR2RGB))\n\n # Draw face detections of each face.\n if not results.detections:\n if debug:\n return image, None\n else:\n return None\n\n if debug:\n annotated\\_image = image.copy()\n for detection in results.detections:\n print(detection.location\\_data.relative\\_bounding\\_box)\n mp\\_drawing.draw\\_detection(annotated\\_image, detection)\n return annotated\\_image, results.detections\n else:\n return results.detections\ndef crop\\_and\\_resize\\_headshot(image, bbox, target\\_width, target\\_height, debug):\n '''\n Crops and resize headshot image\n bbox = realative\\_bbox{xmin, ymin, width, height}\n '''\n # Scale image if needed\n image, image\\_width, image\\_height = scale\\_image\\_to\\_min\\_dim(image, target\\_width, target\\_height)\n\n # Compute face center\n face\\_center\\_x = (bbox.xmin + (0.5 \\* bbox.width)) \\* image\\_width\n face\\_center\\_y = (bbox.ymin + (0.5 \\* bbox.height)) \\* image\\_height\n relative\\_face\\_height = bbox.height\n relative\\_face\\_width = bbox.width\n box\\_height = bbox.height \\* image\\_height\n box\\_width = bbox.width \\* image\\_width\n\n # Mediapipe does not cover the top of the head. So, expand a little bit\n face\\_center\\_y = face\\_center\\_y - (box\\_height \\* FACE\\_HEIGHT\\_EXPANSION\\_FACTOR \\* 0.5)\n box\\_height = box\\_height \\* (1 + FACE\\_HEIGHT\\_EXPANSION\\_FACTOR)\n relative\\_face\\_height = relative\\_face\\_height \\* (1 + FACE\\_HEIGHT\\_EXPANSION\\_FACTOR)\n\n # Target aspect ratio\n # target\\_aspect\\_ratio = float(target\\_width) / target\\_height\n\n # Target coverage.\n # For headshot we expect a minimum face to image dimension ratio of HEADSHOT\\_TARGET\\_COVERAGE\n target\\_coverage = max(TARGET\\_HEADSHOT\\_COVERAGE, relative\\_face\\_width, relative\\_face\\_height)\n print(f'Target Coverage: {target\\_coverage}')\n print(\n f'Max of (Target, rwidth, rheight): {TARGET\\_HEADSHOT\\_COVERAGE}, {relative\\_face\\_width},{relative\\_face\\_height}')\n\n # Factor to scale target dimensions so that the above coverage is met\n initial\\_crop\\_height = image\\_height + 1\n initial\\_crop\\_width = image\\_width + 1\n\n while (initial\\_crop\\_height > image\\_height or initial\\_crop\\_width > image\\_width):\n\n target\\_scaler = box\\_width / \\\n (target\\_coverage \\* target\\_width) if relative\\_face\\_width > relative\\_face\\_height else box\\_height / \\\n (target\\_coverage \\* target\\_height)\n print(f'Target Scaler: {target\\_scaler}')\n\n # Get intial cropping box, that satisfies target\\_coverage\n initial\\_crop\\_width = target\\_width \\* target\\_scaler\n initial\\_crop\\_height = target\\_height \\* target\\_scaler\n\n print(f'Original dims (W x H) : {image\\_width} x {image\\_height}')\n print(f'Initial crop dims (W x H) : {initial\\_crop\\_width} x {initial\\_crop\\_height}')\n\n if initial\\_crop\\_height > image\\_height or initial\\_crop\\_width > image\\_width:\n print('Crop dimensions larger than image! Trying increased coverage')\n target\\_coverage += 0.05\n print(f'Target coverage: {target\\_coverage}')\n print('------------------------------')\n\n if target\\_coverage >= 1.0:\n return None\n\n # Check for valid crop without having to squish the face\n if initial\\_crop\\_width < box\\_width or initial\\_crop\\_height < box\\_height:\n print('Crop Dimensions smaller than face box! Skipping crop!')\n return None\n\n # Get intial bounds\n left\\_x = int(face\\_center\\_x - (initial\\_crop\\_width/2.0))\n right\\_x = int(face\\_center\\_x + (initial\\_crop\\_width/2.0))\n top\\_y = int(face\\_center\\_y - (initial\\_crop\\_height/2.0))\n bottom\\_y = int(face\\_center\\_y + (initial\\_crop\\_height/2.0))\n\n print('Initial Bounds:')\n print(f'lx, ty, rx, by: {left\\_x}, {top\\_y}, {right\\_x}, {bottom\\_y}')\n\n # Slide to bounds\n if left\\_x < 0:\n left\\_x = 0\n right\\_x = int(initial\\_crop\\_width - 1)\n\n if top\\_y < 0:\n top\\_y = 0\n bottom\\_y = int(initial\\_crop\\_height - 1)\n\n if right\\_x >= image\\_width:\n right\\_x = image\\_width - 1\n left\\_x = int(image\\_width - initial\\_crop\\_width)\n\n if bottom\\_y >= image\\_height:\n bottom\\_y = image\\_height - 1\n top\\_y = int(image\\_height - initial\\_crop\\_height)\n\n print('Final Bounds:')\n print(f'lx, ty, rx, by: {left\\_x}, {top\\_y}, {right\\_x}, {bottom\\_y}')\n\n # Get the initial crop\n initial\\_crop = image[top\\_y:bottom\\_y, left\\_x:right\\_x]\n\n # Resize to the target size\n final\\_crop = cv2.resize(initial\\_crop, (target\\_width, target\\_height))\n\n # Pass debug info if requested\n if debug:\n face\\_x1 = int(face\\_center\\_x - box\\_width/2.0)\n face\\_y1 = int(face\\_center\\_y - box\\_height/2.0)\n face\\_x2 = int(face\\_center\\_x + box\\_width/2.0)\n face\\_y2 = int(face\\_center\\_y + box\\_height/2.0)\n\n image = cv2.rectangle(image, (left\\_x, top\\_y), (right\\_x, bottom\\_y), (255, 0, 0), 4)\n image = cv2.rectangle(image, (face\\_x1, face\\_y1), (face\\_x2, face\\_y2), (0, 255, 0), 4)\n return image, final\\_crop\n\n return final\\_crop\ndef crop\\_and\\_resize\\_bodyshot(image, bbox, target\\_width, target\\_height, debug):\n '''\n Crops and resize bodyshot image\n '''\n print('Bodyshot Unimplemented')\n return None\ndef crop\\_and\\_resize\\_person\\_image(image, width, height, debug=False):\n '''\n Given an image, crop and resize the image so that the face/person is the primary subject.\n\n This can be done in the following way:\n 1. Get all faces in the image.\n a. If multiple faces, the biggest one will be the primary face\n 2. Classify if the image is a headshot or a fullbody picture. This can be done by checking the face:image size ratio\n 3. If it is a headshot:\n a. If one of the dimensions is larger, crop such that the whole face is centered. This preserves image quality without \n having to resize.\n b. If one of the dimensions is smaller, crop to that size and then resize\n 4. If it is a full/partial body shot:\n a. Try to preserve the relative face location along the v-axis.\n '''\n\n # Get Detections\n detections = detect\\_faces(image)\n\n # If no detections, return\n if detections is None:\n return None\n\n # Identify the primary face\n max\\_area = 0\n for detection in detections:\n # detection.location\\_data.relative\\_bounding\\_box.{xmin, ymin, width, height}\n bbox = detection.location\\_data.relative\\_bounding\\_box\n area = bbox.height \\* bbox.width\n if area > max\\_area:\n max\\_area = area\n primary\\_detection = detection\n\n # Classify headshot vs body shot\n primary\\_face\\_box = primary\\_detection.location\\_data.relative\\_bounding\\_box\n\n # If face is a certain % of image in either dimension, it's a headshot\n print(f'rW, rH: {primary\\_face\\_box.width}, {primary\\_face\\_box.height}')\n if primary\\_face\\_box.width > HEADSHOT\\_THRESHOLD or primary\\_face\\_box.height > HEADSHOT\\_THRESHOLD:\n print('Classified as a headshot!')\n # Do headshot stuff here\n return crop\\_and\\_resize\\_headshot(image, primary\\_face\\_box, width, height, debug)\n else:\n print('Classified as a bodyshot!')\n # Do body shot stuff here\n return crop\\_and\\_resize\\_bodyshot(image, primary\\_face\\_box, width, height, debug)",
  "has_answer": false
}