{
  "session_id": "sharegpt_iL51bzd_0",
  "session_index": 35,
  "date": "2023/10/01 (Sun) 16:38",
  "turns": [
    {
      "role": "user",
      "content": "EZRA KLEIN: And that streetlight is deep learning.\n\nGARY MARCUS: The streetlight is deep learning. And what\u2019s being ignored, I think, is the rest of cognitive science. So deep learning is a very interesting mathematical technique for setting some values in some system based on data. It turns out to be tremendously useful for a bunch of things.\n\nBut it\u2019s only part of what we need. If you take a step back to cognitive science, which is what I was trained on, and you say, well, what is a human mind? Well, part of it is it does some pattern recognition. And some of what deep learning does is at least part of what we do in pattern recognition. So great.\n\nBut you also, if you look at the human mind, there\u2019s a whole bunch of other things going on. So we use language. When we use language, we go from hearing a sentence to building a model in the world of what the other person\u2019s talking to. We use analogies. We plan things and so forth and so on.\n\nThe reality is we\u2019ve only made progress on a tiny bit of the things that go into intelligence. Now I\u2019m not saying that A.I. has to be exactly like a human. In fact, I think humans are pretty flawed, and we don\u2019t want to just replicate humans. We have, for example, confirmation bias where we notice things in favor of our own theories and not against them. We have all kinds of flaws that we might not want to have in our A.I. systems.\n\nBut there are many things that our A.I. systems can do that aren\u2019t part of what\u2019s fashionable right now and are not under that streetlight that everybody\u2019s looking at. So on a technical level, I think there\u2019s a narrowness to what A.I. has been in the last decade, where there\u2019s this wonderful new tool, but people are a little bit misled about what that tool is actually appropriate for. It\u2019s like if you discovered a power screwdriver and you\u2019d never had one before, that\u2019d be great. But that doesn\u2019t mean that you build the house just with your power screwdriver. And we need other tools here.\n\nThen culturally, and this relates \u2014 there\u2019s been a history that\u2019s actually much older than I am, goes back to the 1940s or \u201950s depending on how you want to count it \u2014 of people who build neural networks in conflict with people who take a more classical approach to A.I., where there\u2019s lots of symbols and trees and databases and reasoning and so forth.\n\nAnd there\u2019s a pendulum that\u2019s gone back and forth. People in the two areas pretty much hate each other, or at least often do. I think it\u2019s getting a little bit better. But there\u2019s a lot of history of hostility between these two areas. So the people with the bigger streetlight right now are the people building the neural networks. And they feel like they\u2019ve been oppressed by the symbolic people, and now they\u2019re oppressing the symbolic people. There\u2019s an old phrase, the victim becomes the victimizer.\n\nSo it\u2019s not a pleasant intellectual area like some fields that I\u2019ve seen. Of course, they\u2019re not always pleasant. But there is definitely a culture right now where the people who are in power and have a lot of money are really trying to shape the decisions around what gets researched and what doesn\u2019t.\n\nEZRA KLEIN: Take a moment and explain what symbol manipulation is because I don\u2019t think that the term for it is very intuitive.\n\nGARY MARCUS: So symbols are just things that stand for other things. And manipulating just means you do stuff with them. So algebra is actually symbol manipulation. So you have an equation like y equals x plus 2. And you have variables in that like y and x. And then you can set those variables to particular instances. So I can say that x is 3. Then I can calculate the value of y from that equation.\n\nSo we do it in algebra. We do it in logic. And linguists like Noam Chomsky would say that we do it in the course of understanding language. It\u2019s also essential to computer programming. Almost everything you see in a computer program is going to be a function that takes variables. You do something with those variables. The variables are symbols. The values that you set those variables are symbols.\n\nThere\u2019s a whole tradition. Most of the world\u2019s software is, in fact, built using software that manipulates symbols, where you describe things abstractly. You also have things like databases, and those databases are symbols. And neural networks have mostly been used as an alternative to that. And they\u2019ve been very effective in some things like speech recognition. But on the other hand, nobody would build a GPS system or a web browser or a word processor using pure neural network approach. Anybody would use mostly symbols for that.\n\nAnd there\u2019s this weird argument, weird discourse where people who like the neural network stuff mostly don\u2019t want to use symbols. What I\u2019ve been arguing for 30 years, since I did my dissertation with Steve Pinker at M.I.T. studying children\u2019s language, has been for some kind of hybrid where we use neural networks for the things they\u2019re good at, and use the symbol stuff for the things they\u2019re good at, and try to find ways to bridge these two traditions.\nSummarize this"
    },
    {
      "role": "assistant",
      "content": "In this conversation, Gary Marcus is discussing the limitations of deep learning, a type of artificial intelligence (AI) that is particularly good at pattern recognition. Marcus argues that while deep learning has proven to be very useful, it is only one part of what is required to build intelligent systems. He points out that the human mind is capable of many other things, such as language use, analogy making, and planning, which are not yet well-understood by AI researchers. Marcus also discusses the longstanding tension between researchers who work on neural networks (like deep learning) and those who work on symbolic AI, which involves the manipulation of symbols to represent and reason about the world. Finally, Marcus comments on the way that funding and cultural dynamics within the field of AI are currently shaping the direction of research."
    }
  ]
}