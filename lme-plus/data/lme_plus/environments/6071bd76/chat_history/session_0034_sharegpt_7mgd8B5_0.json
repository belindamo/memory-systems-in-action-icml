{
  "session_id": "sharegpt_7mgd8B5_0",
  "session_index": 34,
  "date": "2023/07/15 (Sat) 07:38",
  "turns": [
    {
      "role": "user",
      "content": "I have the below dataset, Schedule is another time series inside SnapshotDate time series, and SO\\_CSD, SO\\_CRD, PO\\_CSD, PO\\_CRD vary by SnapshotDate and Schedule (nested time series), Billing vary by SnapshotDate, and Product Category is categorical variable, how could I to predict GR value for each Material using Temporal Fusion Transformer with pytorch\\_forecasting based on Material historical behavior by SnapshotDate trend?\nMaterial SnapshotDate Schedule SO\\_CSD SO\\_CRD PO\\_CSD PO\\_CRD Billing Product Category Cumulative GR\nA 1/31/2022 M1 13 61 79 94 38 Cat 1 89\nA 1/31/2022 M2 54 79 33 64 38 Cat 1 11\nA 1/31/2022 M3 17 57 20 54 38 Cat 1 28\nA 1/31/2022 M4 67 71 66 46 38 Cat 1 12\nA 1/31/2022 M5 65 47 90 15 38 Cat 1 67\nA 1/31/2022 M6 2 60 33 82 38 Cat 1 82\nA 2/28/2022 M1 58 64 49 35 88 Cat 1 57\nA 2/28/2022 M2 68 16 17 49 88 Cat 1 29\nA 2/28/2022 M3 96 20 67 59 88 Cat 1 87\nA 2/28/2022 M4 71 47 2 45 88 Cat 1 26\nA 2/28/2022 M5 92 40 52 41 88 Cat 1 54\nA 2/28/2022 M6 17 61 58 65 88 Cat 1 9\nA 3/31/2022 M1 63 7 94 33 98 Cat 1 67\nA 3/31/2022 M2 72 59 16 82 98 Cat 1 82\nA 3/31/2022 M3 78 78 9 74 98 Cat 1 77\nA 3/31/2022 M4 62 100 36 15 98 Cat 1 71\nA 3/31/2022 M5 58 91 62 76 98 Cat 1 20\nA 3/31/2022 M6 73 28 84 47 98 Cat 1 76\nB 1/31/2022 M1 9 54 54 63 37 Cat 2 70\nB 1/31/2022 M2 27 42 56 26 37 Cat 2 92\nB 1/31/2022 M3 80 93 13 33 37 Cat 2 38\nB 1/31/2022 M4 35 9 40 16 37 Cat 2 40\nB 1/31/2022 M5 9 22 49 78 37 Cat 2 19\nB 1/31/2022 M6 13 47 30 64 37 Cat 2 54\nB 2/28/2022 M1 20 86 42 84 88 Cat 2 80\nB 2/28/2022 M2 4 42 50 74 88 Cat 2 67\nB 2/28/2022 M3 70 97 28 35 88 Cat 2 80\nB 2/28/2022 M4 39 60 38 53 88 Cat 2 84\nB 2/28/2022 M5 77 34 44 49 88 Cat 2 54\nB 2/28/2022 M6 85 88 36 8 88 Cat 2 57\nB 3/31/2022 M1 39 47 54 23 23 Cat 2 71\nB 3/31/2022 M2 44 9 84 14 23 Cat 2 36\nB 3/31/2022 M3 65 30 50 94 23 Cat 2 5\nB 3/31/2022 M4 67 52 2 13 23 Cat 2 30\nB 3/31/2022 M5 17 59 92 49 23 Cat 2 96\nB 3/31/2022 M6 45 61 68 88 23 Cat 2 98"
    },
    {
      "role": "assistant",
      "content": "To predict the GR value for each material using the Temporal Fusion Transformer (TFT) with PyTorch Forecasting, you should follow these steps:\n\n1. Install PyTorch Forecasting:\n```\npip install pytorch-forecasting\n```\n1. Import necessary libraries:\n```python\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport torch\nfrom pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, BaseModel\nfrom pytorch_forecasting.data import GroupNormalizer\nfrom pytorch_forecasting.metrics import SMAPE\nfrom pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n```\n1. Load and preprocess the dataset:\n```python\n# Load the dataset (use your own data source)\ndata = pd.read_csv(\"data.csv\")\n\n# Convert date columns to datetime\ndata['SnapshotDate'] = pd.to_datetime(data['SnapshotDate'])\n\n# Map Product Category to integers\ndata['Product Category'] = data['Product Category'].astype('category').cat.codes\n\n# Create a time index for the dataset\ndata['time_idx'] = (data['SnapshotDate'].dt.year - 2022) * 12 + data['SnapshotDate'].dt.month\n\n# Set the max_prediction_length and max_encoder_length\nmax_prediction_length = 6\nmax_encoder_length = 12\n\n# Create a training dataset\ntraining_cutoff = data['time_idx'].max() - max_prediction_length\n\n# Split the data into training and validation\ntraining = TimeSeriesDataSet(\n    data[data.time_idx <= training_cutoff],\n    time_idx=\"time_idx\",\n    target=\"Cumulative GR\",\n    group_ids=[\"Material\"],\n    min_encoder_length=max_encoder_length,\n    max_encoder_length=max_encoder_length,\n    min_prediction_length=max_prediction_length,\n    max_prediction_length=max_prediction_length,\n    static_categoricals=[\"Product Category\"],\n    static_reals=[],\n    time_varying_known_categoricals=[],\n    time_varying_known_reals=[\"time_idx\", \"SO_CSD\", \"SO_CRD\", \"PO_CSD\", \"PO_CRD\", \"Billing\"],\n    time_varying_unknown_categoricals=[],\n    time_varying_unknown_reals=[\"Cumulative GR\"],\n    target_normalizer=GroupNormalizer(groups=[\"Material\"], transformation=\"softplus\"),\n    add_relative_time_idx=True,\n    add_target_scales=True,\n    add_encoder_length=True,\n)\n\n# Create a validation dataset\nvalidation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n```\n1. Find optimal hyperparameters:\n```python\n# Find the optimal hyperparameters\nstudy = optimize_hyperparameters(\n    training,\n    validation,\n    model_path=\"optuna_test\",\n    n_trials=100,\n    max_epochs=50,\n    gradient_clip_val_range=(0.01, 1.0),\n    hidden_size_range=(8, 128),\n    hidden_continuous_size_range=(8, 128),\n    attention_head_size_range=(1, 4),\n    learning_rate_range=(0.001, 0.1),\n    dropout_range=(0.1, 0.3),\n    trainer_kwargs=dict(limit_train_batches=30),\n    reduce_on_plateau_patience=4,\n    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate\n)\n```\n1. Train the model:\n```python\n# Instantiate the Temporal Fusion Transformer with optimal hyperparameters\nmodel = TemporalFusionTransformer.from_hyperparameters(study.best_trial.params)\n\n# Train the model\ntrainer = torch.optim.swa_utils.SWALR(\n    model,\n    anneal_strategy=\"cos\",\n    anneal_epochs=5,\n    swa_lr=study.best\n```"
    }
  ]
}