{
  "turn_global_index": 34,
  "session_index": 3,
  "session_id": "sharegpt_4YrP1Ej_37",
  "turn_in_session": 0,
  "date": "2023/05/21 (Sun) 13:47",
  "role": "assistant",
  "content": "Sure, here's an updated implementation of `s3.py` that raises a `S3OperationException` when an error occurs during the S3 upload or download operations:\n```python\nimport boto3\nimport os\nfrom ..exceptions import S3OperationException\nclass S3Uploader:\n    def __init__(self, bucket_name):\n        self.s3 = boto3.client(\"s3\")\n        self.bucket_name = bucket_name\n\n    def upload_directory(self, directory, checksum_file_path):\n        try:\n            for root, dirs, files in os.walk(directory):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    relative_path = os.path.relpath(file_path, directory)\n                    s3_key = os.path.join(os.path.basename(directory), relative_path)\n                    self.s3.upload_file(file_path, self.bucket_name, s3_key, ExtraArgs={\n                        \"Metadata\": {\n                            \"checksum\": self._get_checksum(relative_path, checksum_file_path)\n                        }\n                    })\n        except Exception as e:\n            raise S3OperationException(f\"Failed to upload directory to S3: {e}\")\n\n    def _get_checksum(self, relative_path, checksum_file_path):\n        with open(checksum_file_path, \"r\") as f:\n            for line in f.readlines():\n                parts = line.strip().split(\",\")\n                if parts[0] == relative_path:\n                    return parts[1]\n        return \"\"\n\nclass S3Downloader:\n    def __init__(self, bucket_name):\n        self.s3 = boto3.client(\"s3\")\n        self.bucket_name = bucket_name\n\n    def download_directory(self, directory, checksum_file_path):\n        try:\n            for root, dirs, files in os.walk(directory):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    relative_path = os.path.relpath(file_path, directory)\n                    s3_key = os.path.join(os.path.basename(directory), relative_path)\n                    s3_object = self.s3.get_object(Bucket=self.bucket_name, Key=s3_key)\n                    with open(file_path, \"wb\") as f:\n                        f.write(s3_object[\"Body\"].read())\n                    checksum = s3_object[\"Metadata\"].get(\"checksum\", \"\")\n                    expected_checksum = self._get_checksum(relative_path, checksum_file_path)\n                    if checksum != expected_checksum:\n                        raise S3OperationException(\"Checksum mismatch\")\n        except Exception as e:\n            raise S3OperationException(f\"Failed to download directory from S3: {e}\")\n\n    def _get_checksum(self, relative_path, checksum_file_path):\n        with open(checksum_file_path, \"r\") as f:\n            for line in f.readlines():\n                parts = line.strip().split(\",\")\n                if parts[0] == relative_path:\n                    return parts[1]\n        return \"\"\n```\nThe `S3Uploader` class raises a `S3OperationException` if an error occurs during the S3 upload operation, while the `S3Downloader` class raises a `S3OperationException` if an error occurs during the S3 download operation.\n\nBy using custom exception classes, we can provide more detailed and specific error messages that can help with debugging and troubleshooting.",
  "has_answer": false
}