{
  "turn_global_index": 38,
  "session_index": 3,
  "session_id": "sharegpt_4YrP1Ej_37",
  "turn_in_session": 4,
  "date": "2023/03/06 (Mon) 08:58",
  "role": "assistant",
  "content": "Apologies, it looks like my previous message was cut off. Here's the full updated implementation of the `processor.py` module with the main method and imports:\n```python\nimport argparse\nimport os\nimport shutil\nimport sys\nfrom .exceptions import (\n    HdfsOperationException, GpfsOperationException, EncryptionException,\n    CompressionException, ChecksumException, S3OperationException\n)\nfrom .hdfs import HdfsUploader, HdfsDownloader\nfrom .gpfs import GpfsUploader, GpfsDownloader\nfrom .encryption import encrypt_directory\nfrom .compression import zip_directory, unzip_directory\nfrom .checksum import generate_checksum, write_checksum\nfrom .s3 import S3Uploader, S3Downloader\nclass Processor:\n    def __init__(self, process_name, operation, data_source_type, data_source_path, encryption_needed,\n                 zipping_needed, checksum_needed, s3_upload, archive_needed, process_sub_folder_path=\"\", s3_path=\"\"):\n        self.process_name = process_name\n        self.operation = operation\n        self.data_source_type = data_source_type\n        self.data_source_path = data_source_path\n        self.encryption_needed = encryption_needed\n        self.zipping_needed = zipping_needed\n        self.checksum_needed = checksum_needed\n        self.s3_upload = s3_upload\n        self.archive_needed = archive_needed\n        self.process_sub_folder_path = process_sub_folder_path\n        self.s3_path = s3_path\n\n    def run(self):\n        # Create working directory\n        working_directory = os.path.abspath(self.process_name)\n        if not os.path.exists(working_directory):\n            os.mkdir(working_directory)\n\n        # Download files from data source\n        if self.operation == \"download\":\n            if self.data_source_type == \"hdfs\":\n                downloader = HdfsDownloader()\n            elif self.data_source_type == \"gpfs\":\n                downloader = GpfsDownloader()\n            else:\n                raise ValueError(\"Invalid data source type\")\n\n            downloader.download_directory(self.data_source_path, working_directory)\n\n            if self.s3_upload:\n                if not os.path.exists(self.process_sub_folder_path):\n                    os.makedirs(self.process_sub_folder_path)\n\n                s3_downloader = S3Downloader(bucket_name=\"my-bucket\")\n                s3_downloader.download_directory(self.s3_path, self.process_sub_folder_path)\n\n                checksum_file_path = os.path.join(self.process_sub_folder_path, \"checksums.csv\")\n                if not os.path.exists(checksum_file_path):\n                    raise S3OperationException(\"Missing checksum file in S3\")\n\n                expected_checksums = generate_checksum(working_directory)\n                with open(checksum_file_path, \"r\") as f:\n                    for line in f:\n                        parts = line.strip().split(\",\")\n                        relative_path = parts[0]\n                        expected_checksum = expected_checksums.get(relative_path, \"\")\n                        actual_checksum = parts[1]\n                        if expected_checksum != actual_checksum:\n                            raise S3OperationException(\"Checksum mismatch in S3\")\n\n        # Encrypt files\n        if self.encryption_needed:\n            try:\n                encrypt_directory(working_directory)\n            except EncryptionException as e:\n                print(f\"Failed to encrypt files: {e}\", file=sys.stderr)\n                return\n\n        # Zip files\n        if self.zipping_needed:\n            try:\n                zip_directory(working_directory, self.encryption_needed)\n            except CompressionException as e:\n                print(f\"Failed to zip files: {e}\", file=sys.stderr)\n                return\n\n        # Generate checksums\n        if self.checksum_needed:\n            checksums = generate_checksum(working_directory)\n            checksum_file_path = os.path.join(working_directory, \"checksums.csv\")\n            try:\n                write_checksum(checksums, checksum_file_path)\n            except Checksum\n```",
  "has_answer": false
}