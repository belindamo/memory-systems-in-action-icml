{
  "turn_global_index": 241,
  "session_index": 23,
  "session_id": "sharegpt_rolT4Nz_28",
  "turn_in_session": 4,
  "date": "2023/02/14 (Tue) 04:01",
  "role": "user",
  "content": "## The Speech Signal Representation - Mel Spectrograms\nHumans can recognize and differentiate different speech sounds based on the frequency characteristics of the sounds. For machine learning applications, human speech is represented using spectro-temporal features in the [Mel-scale](https://en.wikipedia.org/wiki/Mel\\_scale) extracted from the speech sample. Mel-scale features are inspired by human speech perception and auditory processing whereby the human ear has difference sensitivity (or resolution) in differet frequency bandes. That is, the human ear can better recognize differences in in lower range frequences, while higher range frequences have a lower resolution. The Mel-scale is linear for frequencies in the range (0-1kHz), and logarithmic for frequencies above 1kHz.\n\nIn the spectro-temporal representation of speech, a speech sample can be seen as a sequence of $T$ spectral vectors as $\\mathbf{X} = (\\mathbf{x}^1, \\mathbf{x}^2, \\dots, \\mathbf{x}^T)$. Each spectral vector $\\mathbf{x}^t \\in \\mathbb{R}^{k}$ at time-step $t$ is extracted from a short speech segment (~25 milliseconds) with the assumption that the signal is time-invariant in this small time window. Here, $k$ is the number of frequency bands in the [spectrogram](https://en.wikipedia.org/wiki/Spectrogram) and this is a parameter of the feature extraction pipeline. The representation is based on the Fourier transform to convert the temporal signal into the frequency domain. \n\nIn automatic speech recognition (ASR) research and applications, spectral vectors are usually referred to as \"acoustic frames\". Morover, adjacent frames are extracted with some overlap between them, usually ~10 milliseconds. \n\ndef extract\\_melspectrogram(signal, sr, num\\_mels):\n \"\"\"\n Given a time series speech signal (.wav), sampling rate (sr), \n and the number of mel coefficients, return a mel-scaled \n representation of the signal as numpy array.\n \"\"\"\n \n mel\\_features = librosa.feature.melspectrogram(y=signal,\n sr=sr,\n n\\_fft=200, # with sampling rate = 8000, this corresponds to 25 ms\n hop\\_length=80, # with sampling rate = 8000, this corresponds to 10 ms\n n\\_mels=num\\_mels, # number of frequency bins, use either 13 or 39\n fmin=50, # min frequency threshold\n fmax=4000 # max frequency threshold, set to SAMPLING\\_RATE/2\n )\n \n # for numerical stability added this line\n mel\\_features = np.where(mel\\_features == 0, np.finfo(float).eps, mel\\_features)\n\n # 20 \\* log10 to convert to log scale\n log\\_mel\\_features = 20\\*np.log10(mel\\_features)\n\n # feature scaling\n scaled\\_log\\_mel\\_features = preprocessing.scale(log\\_mel\\_features, axis=1)\n \n return scaled\\_log\\_mel\\_features\n\nplease wait for my inputs",
  "has_answer": false
}